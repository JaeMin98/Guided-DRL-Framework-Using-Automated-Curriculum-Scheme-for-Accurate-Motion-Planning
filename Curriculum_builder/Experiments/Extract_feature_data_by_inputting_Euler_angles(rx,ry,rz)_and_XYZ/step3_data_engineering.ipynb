{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"data_points\"\n",
    "if not os.path.exists(csv_path): os.makedirs(csv_path)\n",
    "log_path =  os.path.join(csv_path, 'logs')\n",
    "if not os.path.exists(log_path): os.makedirs(log_path)\n",
    "\n",
    "# Variables for OutlierRemover Class\n",
    "origin_csv_path = os.path.join(csv_path, 'data_points_origin.csv')\n",
    "outlier_removed_csv_path = os.path.join(csv_path, 'outlier_removed_data_points.csv')\n",
    "lower_outliers_path =   os.path.join(log_path, 'lower_outliers.csv')\n",
    "upper_outliers_path = os.path.join(log_path, 'upper_outliers.csv')\n",
    "\n",
    "# Variable for DataNormalizer Class\n",
    "normalized_csv_path = os.path.join(csv_path, 'normalized_data_points.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemover:\n",
    "    def __init__(self, filepath):\n",
    "        \"\"\"Initialize the DataFrame by taking the path to the CSV file\"\"\"\n",
    "        self.origin_data = pd.read_csv(filepath)\n",
    "    \n",
    "    def remove_outliers(self, column_index):\n",
    "        \"\"\"Calculates the IQR for the specified column index and removes rows with outliers\"\"\"\n",
    "        # Select that column\n",
    "        col_values = self.origin_data.iloc[:, column_index]\n",
    "        \n",
    "        # Calculate IQRs\n",
    "        Q1 = col_values.quantile(0.25)\n",
    "        Q3 = col_values.quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        # Calculate outlier boundary values\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        # Filtering outliers\n",
    "        self.lower_outliers = self.origin_data[(col_values < lower_bound)]\n",
    "        self.upper_outliers = self.origin_data[(col_values > upper_bound)]\n",
    "        self.data = self.origin_data[(col_values >= lower_bound) & (col_values <= upper_bound)]\n",
    "\n",
    "    \n",
    "    def save_data(self, output_filepath):\n",
    "        self.data.to_csv(output_filepath, index=False)\n",
    "        print(f\"Outlier removed csv file was created in -> {output_filepath}\")\n",
    "\n",
    "    def save_outliers_data(self, lower_outlier_path, upper_outlier_path):\n",
    "        self.lower_outliers.to_csv(lower_outlier_path, index=False)\n",
    "        print(f\"Data detected as outliers stored in (lower bound) -> {lower_outlier_path}\")\n",
    "        self.upper_outliers.to_csv(upper_outlier_path, index=False)\n",
    "        print(f\"Data detected as outliers stored in (upper bound) -> {upper_outlier_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outlier removed csv file was created in -> data_points/outlier_removed_data_points.csv\n",
      "Data detected as outliers stored in (lower bound) -> data_points/logs/lower_outliers.csv\n",
      "Data detected as outliers stored in (upper bound) -> data_points/logs/upper_outliers.csv\n"
     ]
    }
   ],
   "source": [
    "remover = OutlierRemover(origin_csv_path)\n",
    "remover.remove_outliers(column_index=3)  # Detect outliers based on the 4th index (run_time)\n",
    "remover.save_data(outlier_removed_csv_path)\n",
    "remover.save_outliers_data(lower_outliers_path, upper_outliers_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Origin data length : 26072\n",
      "Outliers removed data length : 26072\n",
      "Lower outliers length : 0\n",
      "Upper outliers length : 0\n"
     ]
    }
   ],
   "source": [
    "print( f\"Origin data length : {len(remover.origin_data)}\" )\n",
    "print( f\"Outliers removed data length : {len(remover.data)}\")\n",
    "print( f\"Lower outliers length : {len(remover.lower_outliers)}\")\n",
    "print( f\"Upper outliers length : {len(remover.upper_outliers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataNormalizer:\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        self.data = self.load_data()\n",
    "\n",
    "    def load_data(self):\n",
    "        return pd.read_csv(self.filepath)\n",
    "\n",
    "    def normalize_columns(self, normalized_filepath, num_of_data=None):\n",
    "        \"\"\" Methods to normalize data from the 4th to the last column The data is scaled to values between 0 and 1 using the Min-Max normalization method\"\"\"\n",
    "        scaler = MinMaxScaler()\n",
    "        self.data.iloc[:, 7:] = scaler.fit_transform(self.data.iloc[:, 7:])\n",
    "        self.save_data(normalized_filepath, num_of_data)\n",
    "    \n",
    "    def save_data(self, normalized_filepath, num_of_data = None):\n",
    "\n",
    "        self.data.columns = ['target_X', 'target_Y', 'target_Z', 'qX', 'qY', 'qZ', 'qW', 'execution_time','distance', 'angle',\n",
    "                'delta_of_6_axis', 'delta_of_3_axis', 'joint1', 'joint2', 'joint3', 'joint4', 'joint5', 'joint6']\n",
    "        print(self.data)\n",
    "        if(num_of_data == None):\n",
    "            self.data.to_csv(normalized_filepath, index=False)\n",
    "        else:\n",
    "            sampled_data = self.data.sample(n=num_of_data, random_state=42)\n",
    "            sampled_data.to_csv(normalized_filepath, index=False)\n",
    "            print( f\"Number of data changes based on \\\"num_of_data\\\" : ( {len(self.data)} ) -> ( {num_of_data} )\" )\n",
    "            \n",
    "        print(f\"Normalized csv file was created in -> {normalized_filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       target_X  target_Y  target_Z        qX        qY        qZ        qW  \\\n",
      "0      0.407835 -0.091812  0.277702  0.529772  0.798300 -0.265650  0.107187   \n",
      "1      0.332240  0.041342  0.367651 -0.166518  0.601058  0.643329  0.443992   \n",
      "2      0.332240 -0.041342  0.367651 -0.497223  0.394335  0.111699  0.764717   \n",
      "3      0.248779  0.110235  0.556648  0.143136  0.594339  0.146564  0.777684   \n",
      "4      0.248779 -0.110235  0.556648  0.159327  0.160650  0.413660  0.881868   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "26067 -0.178982 -0.115989  0.336106  0.616161 -0.485311 -0.506064  0.358772   \n",
      "26068  0.039205  0.148916  0.588626 -0.133729 -0.515472  0.825561  0.186691   \n",
      "26069  0.039205 -0.148916  0.588626  0.574291  0.226231  0.774710  0.137236   \n",
      "26070  0.003638  0.251871  0.379837  0.044613 -0.186592 -0.917812  0.347583   \n",
      "26071  0.003638 -0.251871  0.379837 -0.099657  0.751856 -0.589641  0.277676   \n",
      "\n",
      "       execution_time  distance     angle  delta_of_6_axis  delta_of_3_axis  \\\n",
      "0            0.042201  0.262857  0.359439         0.294677         0.270551   \n",
      "1            0.034340  0.103489  0.266948         0.242836         0.105193   \n",
      "2            0.019652  0.103488  0.447104         0.318497         0.129398   \n",
      "3            0.013653  0.191894  0.222302         0.279069         0.326882   \n",
      "4            0.010550  0.191853  0.237816         0.164357         0.363374   \n",
      "...               ...       ...       ...              ...              ...   \n",
      "26067        0.026893  0.567020  0.603230         0.582362         0.555418   \n",
      "26068        0.039719  0.373914  0.529758         0.351829         0.458035   \n",
      "26069        0.043442  0.373916  0.204092         0.443859         0.363281   \n",
      "26070        0.027513  0.439180  0.740289         0.302605         0.290102   \n",
      "26071        0.024824  0.439174  0.534179         0.419022         0.302487   \n",
      "\n",
      "         joint1    joint2    joint3    joint4    joint5    joint6  \n",
      "0      0.065810  0.458572  0.413518  0.281647  0.737592  0.195319  \n",
      "1      0.020642  0.222519  0.160235  0.608463  0.637757  0.176342  \n",
      "2      0.061937  0.225590  0.167501  0.630133  0.660620  0.384933  \n",
      "3      0.142843  0.232570  0.736958  0.408302  0.328131  0.210252  \n",
      "4      0.140946  0.289111  0.810377  0.045578  0.191945  0.075178  \n",
      "...         ...       ...       ...       ...       ...       ...  \n",
      "26067  0.849090  0.131726  0.351455  0.767290  0.325084  0.591035  \n",
      "26068  0.430665  0.141972  0.778134  0.086365  0.894975  0.032081  \n",
      "26069  0.476472  0.016688  0.484436  0.852994  0.749001  0.092029  \n",
      "26070  0.512922  0.017788  0.142208  0.107041  0.785294  0.289727  \n",
      "26071  0.544083  0.020415  0.125534  0.769301  0.325105  0.524552  \n",
      "\n",
      "[26072 rows x 18 columns]\n",
      "Normalized csv file was created in -> data_points/normalized_data_points.csv\n"
     ]
    }
   ],
   "source": [
    "normalizer = DataNormalizer(outlier_removed_csv_path) \n",
    "normalized_data = normalizer.normalize_columns(normalized_csv_path) #num_of_data can be used to determine the number of data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
